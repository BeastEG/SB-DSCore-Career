{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0848e79",
   "metadata": {},
   "source": [
    "## 5) Modeling\n",
    "\n",
    "In this notebook, we'll begin evaluating how we can model our data and see how well some basic evaluation practices can create a recommendation system! To begin with, we'll set consider some of the framework we should work within"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11295a2e",
   "metadata": {},
   "source": [
    "#### Baseline Performance Criteria\n",
    "\n",
    "We'll be using the Root Mean Squared Error (RMSE) metric to evaluate how good (or bad) our model is as a simple baseline:\n",
    "\n",
    "RMSE: $\\sqrt{\\frac{\\sum(\\hat y - y)^2}{n}}$\n",
    "\n",
    "In addition, we should consider what the \"absolute\" worst score we can get would be. Since our values for ratings can only go from 1 to 5 in integer values, the most we can be \"off\" is 4. This means the RMSE at \"maximum\" can be 4, which gives us a frame of reference for an absolute disaster of a model!\n",
    "\n",
    "However, another thing to consider is that we could just guess the median rating for everything (\"3\") and get a sense of how well that would do in terms of RMSE in relation to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40e9c874",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import relevant baseline packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7efe85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a RMSE function\n",
    "def compute_rmse(y_true, y_pred):\n",
    "    \"\"\"Compute Root Mean Squared Error.\"\"\"\n",
    "    \n",
    "    return np.sqrt(np.mean(np.power(y_true - y_pred, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48c8e56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load in our testing and training sets\n",
    "data_TRAINING = pd.read_csv('DF_TRAINING.csv')\n",
    "data_TESTING = pd.read_csv('DF_TESTING.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82cb6db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the redundant column \"Unnamed: 0\"\n",
    "data_TRAINING.drop(['Unnamed: 0'],axis= 1,inplace = True)\n",
    "data_TESTING.drop(['Unnamed: 0'],axis= 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16437cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79223 entries, 0 to 79222\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   user_id      79223 non-null  int64 \n",
      " 1   movie_id     79223 non-null  int64 \n",
      " 2   rating       79223 non-null  int64 \n",
      " 3   timestamp    79223 non-null  int64 \n",
      " 4   movie_title  79223 non-null  object\n",
      " 5   testing      79223 non-null  int64 \n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data_TRAINING.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46694ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20502 entries, 0 to 20501\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   user_id      20502 non-null  int64 \n",
      " 1   movie_id     20502 non-null  int64 \n",
      " 2   rating       20502 non-null  int64 \n",
      " 3   timestamp    20502 non-null  int64 \n",
      " 4   movie_title  20502 non-null  object\n",
      " 5   testing      20502 non-null  int64 \n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 961.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data_TESTING.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f22a6273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>testing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>308</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>887736532</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>891700426</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>878962392</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>882181396</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>875379445</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp       movie_title  testing\n",
       "0      308         1       4  887736532  Toy Story (1995)        1\n",
       "1      280         1       4  891700426  Toy Story (1995)        1\n",
       "2      181         1       3  878962392  Toy Story (1995)        1\n",
       "3      145         1       3  882181396  Toy Story (1995)        1\n",
       "4       67         1       3  875379445  Toy Story (1995)        1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_TESTING.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f360de25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## I'm going to create a unique holder DataFrame that will hold our y_true values and all the different y_preds\n",
    "## We will make throughout this capstone. This is so we can store the values and pull them out if necessary\n",
    "## to avoid having to re-run the models again\n",
    "results_table = pd.DataFrame(columns=['user_id','movie_id','y_true','y_pred_naive','y_pred_average','y_pred_euc_sim','y_pred_cosine_sim'])\n",
    "results_table['user_id'] = data_TESTING['user_id']\n",
    "results_table['movie_id'] = data_TESTING['movie_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "194c0d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 99725 entries, 0 to 20501\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   user_id      99725 non-null  int64 \n",
      " 1   movie_id     99725 non-null  int64 \n",
      " 2   rating       99725 non-null  int64 \n",
      " 3   timestamp    99725 non-null  int64 \n",
      " 4   movie_title  99725 non-null  object\n",
      " 5   testing      99725 non-null  int64 \n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Let's make a 'complete' data table as well in case it comes in handy\n",
    "data_COMPLETE = pd.concat([data_TRAINING,data_TESTING],axis=0)\n",
    "data_COMPLETE.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6395bf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The naive guess of median value \"3\" RMSE is: 1.2401007885881654\n"
     ]
    }
   ],
   "source": [
    "# Let's do a quick check of the \"median\" rating of 3 against our Testing Data Set\n",
    "results_table['y_true'] = np.array(data_TESTING['rating'])\n",
    "results_table['y_pred_naive'] = np.full(shape=len(results_table['y_true']),fill_value=3)\n",
    "RMSE_naive = compute_rmse(results_table['y_true'], results_table['y_pred_naive'])\n",
    "print(f'The naive guess of median value \"3\" RMSE is: {RMSE_naive}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6050799",
   "metadata": {},
   "source": [
    "We can now move to trying out some methods of developing a rating prediction for our movies. First, we'll apply an unweighted average between all the ratings in our testing set for a given movie\n",
    "\n",
    "#### Averaging across users for a movie\n",
    "\n",
    "The first prediction we can make is by simply taking the average for all the users in our testing set for a given movie and then making that the prediction for the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0de3f798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.894737</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.180952</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.027778</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.572289</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.318841</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>1639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>3.333333</td>\n",
       "      <td>1643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1473 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating  movie_id\n",
       "0     3.894737         1\n",
       "1     3.180952         2\n",
       "2     3.027778         3\n",
       "3     3.572289         4\n",
       "4     3.318841         5\n",
       "...        ...       ...\n",
       "1468  4.500000      1639\n",
       "1469  3.333333      1643\n",
       "1470  2.000000      1652\n",
       "1471  3.000000      1658\n",
       "1472  4.000000      1664\n",
       "\n",
       "[1473 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, let's make a table that calculates the mean for each movie in the training set\n",
    "mean_table_TRAINING = data_TRAINING[['movie_title','movie_id','rating']].groupby('movie_id').mean('rating')\n",
    "mean_table_TRAINING['movie_id']=mean_table_TRAINING.index\n",
    "mean_table_TRAINING.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f7b5236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second, we'll need to make a prediction array\n",
    "meanPredictHolder = data_TESTING\n",
    "meanPredictHolder['predict'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a28dad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third, we'll need a method of assigning the correct prediction which we can generate a function:\n",
    "def vlookup_assign(df_test, mean_table):\n",
    "    \"This will emulate a vlookup function\"\n",
    "    for counter in range(0,len(df_test)):\n",
    "        movieID = df_test.iloc[counter,1]\n",
    "        meanPredict = mean_table.loc[mean_table['movie_id']== movieID]\n",
    "        df_test.iloc[counter,6] = meanPredict\n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7727ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourth, let's run our model\n",
    "results = vlookup_assign(meanPredictHolder,mean_table_TRAINING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a75ce84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean guess across training set users for any given movie RMSE is: 1.0299732829945232\n"
     ]
    }
   ],
   "source": [
    "# Fifth, let's evaluate the results of our model\n",
    "#y_true = np.array(results['rating'])\n",
    "results_table['y_pred_average'] = np.array(meanPredictHolder['predict'])\n",
    "RMSE_means = compute_rmse(results_table['y_true'], results_table['y_pred_average'])\n",
    "print(f'The mean guess across training set users for any given movie RMSE is: {RMSE_means}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c9d698",
   "metadata": {},
   "source": [
    "The result of averaging across users is a RMSE of approximately 1.03 whereas our naive guess of \"3\" for everything resulted in a RMSE approxiamately of 1.24. This saw our RMSE decrease by about 16.94% which is fairly good amount of improvement considering the straight-forward approach we are using to make the prediction. Let's see if we can get the prediction even more accurate by starting to account for how similar or dissimilar a user is in relation to the other users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edef847",
   "metadata": {},
   "source": [
    "#### Prediction using similarity measures\n",
    "\n",
    "For this method, we will consider not only the movie rating that needs to be predicted but also the specific 'user' we are making the prediction for regarding the movie. The logic here is that every person is different and that the better we can account for these differences, the more accurate our predictions will be. In terms of a methodology, this will be more in-depth to consider than the more straight-forward metrics we just used so we'll need to consider how we go through this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46aba5a",
   "metadata": {},
   "source": [
    "There are some considerations we need to make when trying to use similarities. First, we need to make sure to avoid data leakage  (letting testing data affect the training data or training process), which means if we create some data structures to support the process of making similarity measures, none of the testing data can be inside the data structure. Second, we'll need to consider how to handle \"blank\" values (i.e., what happens when two users are being compared against a specific movie but one or the other hasn't rated a different movie). For the time being, we'll treat any blank value as a \"zero\" to faciliate proper calculations. Third, we need a structure that will allow us to compare users, which would imply that a pivot table may be a place to start as it allows for us to create a more straight-forward table to compare users and their ratings for any given movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75d60813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>testing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>287</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>875334088</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>877019411</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>883601324</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>875635748</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>880563619</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp       movie_title  testing\n",
       "0      287         1       5  875334088  Toy Story (1995)        0\n",
       "1      148         1       4  877019411  Toy Story (1995)        0\n",
       "2       66         1       3  883601324  Toy Story (1995)        0\n",
       "3        5         1       4  875635748  Toy Story (1995)        0\n",
       "4      109         1       4  880563619  Toy Story (1995)        0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check our training data\n",
    "data_TRAINING.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b90bd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In terms of a pivot table, we'd in essence have rows be user_id and each column would be a rating for each movie\n",
    "train_user_movie_rating_mtx = data_TRAINING.pivot_table(values='rating', index='user_id', columns='movie_id', fill_value=0)\n",
    "test_user_movie_rating_mtx = data_TESTING.pivot_table(values='rating', index='user_id', columns='movie_id', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cd40e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movie_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1615</th>\n",
       "      <th>1620</th>\n",
       "      <th>1622</th>\n",
       "      <th>1623</th>\n",
       "      <th>1628</th>\n",
       "      <th>1639</th>\n",
       "      <th>1643</th>\n",
       "      <th>1652</th>\n",
       "      <th>1658</th>\n",
       "      <th>1664</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1473 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movie_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
       "user_id                                                               ...   \n",
       "0            0     0     0     0     0     0     0     0     0     0  ...   \n",
       "1            5     3     4     0     0     0     4     1     5     3  ...   \n",
       "2            4     0     0     0     0     0     0     0     0     2  ...   \n",
       "3            0     0     0     0     0     0     0     0     0     0  ...   \n",
       "4            0     0     0     0     0     0     0     0     0     0  ...   \n",
       "\n",
       "movie_id  1615  1620  1622  1623  1628  1639  1643  1652  1658  1664  \n",
       "user_id                                                               \n",
       "0            0     0     0     0     0     0     0     0     0     0  \n",
       "1            0     0     0     0     0     0     0     0     0     0  \n",
       "2            0     0     0     0     0     0     0     0     0     0  \n",
       "3            0     0     0     0     0     0     0     0     0     0  \n",
       "4            0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 1473 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user_movie_rating_mtx.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "857acbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need a list that allows us to indentify the correct movie index for our columns.\n",
    "#We don't need this for the user_id as we checked that it is a complete sequence from 1 to the nth user\n",
    "columnPlaceKey = list(train_user_movie_rating_mtx.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c644edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>testing</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>308</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>887736532</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>1</td>\n",
       "      <td>3.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>891700426</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>1</td>\n",
       "      <td>3.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>878962392</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>1</td>\n",
       "      <td>3.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>882181396</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>1</td>\n",
       "      <td>3.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>875379445</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>1</td>\n",
       "      <td>3.894737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp       movie_title  testing   predict\n",
       "0      308         1       4  887736532  Toy Story (1995)        1  3.894737\n",
       "1      280         1       4  891700426  Toy Story (1995)        1  3.894737\n",
       "2      181         1       3  878962392  Toy Story (1995)        1  3.894737\n",
       "3      145         1       3  882181396  Toy Story (1995)        1  3.894737\n",
       "4       67         1       3  875379445  Toy Story (1995)        1  3.894737"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_TESTING.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4c2489",
   "metadata": {},
   "source": [
    "#### Similarity Measure: Euclidean\n",
    "\n",
    "We can use a variety of similarity measures but the first one we'll use is a typical \"baseline\" which is Euclidean similarity which has it's foundation in the standard definition of distance from geometery.\n",
    "\n",
    "$$ sim(x,y) = \\frac{1}{1 + \\sqrt{\\sum (x - y)^2}}$$\n",
    "\n",
    "The way our measure works is that it has an asymotic minimum value of 0 (without reaching it) and a maximum value of 1 (1/1) which allows us to gather weights. As a note, this version it to help take care of edge cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86024c7",
   "metadata": {},
   "source": [
    "#### Process Steps\n",
    "\n",
    "The next portion of the analysis requires us to create a framework that allows us to craft together measures. In terms of an algorithm, we'll consider the following steps:\n",
    "\n",
    "1) Identifying the movie to be predicted and the user associated with it which we'll do by pulling from the testing data a user_id and a movie_id\n",
    "\n",
    "2) Subset the testing data by extracting all users who have rated the movie in question and pulling the information about the specific user we are making the prediction for.\n",
    "\n",
    "3) Create an array framework that allows for us to calculate the Euclidean distance for each user that results in a weighting scheme\n",
    "\n",
    "4) Calculate the new weighted average for the movie rating that will become our rating prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8883ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_sim(s1,s2):\n",
    "    \"Gives us the similarity in terms of euclidean distance of two series\"\n",
    "    diff = s1 - s2\n",
    "    return (1 / (1+np.sqrt(np.sum(diff ** 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "241dfe9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BERKEG~1\\AppData\\Local\\Temp/ipykernel_25960/2406729010.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_user_movie_holder['prediction'] = 0 ## Make feature column for our predictions\n",
      "C:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "#This will be our major process holder that we can simply change with different similarity functions\n",
    "#!!! Warning - This takes a lot of time if you run the entire testing set !!!\n",
    "test_user_movie_holder = data_TESTING[['movie_id','user_id','rating']] ## Create a 'list' of the items to predict\n",
    "test_user_movie_holder['prediction'] = 0 ## Make feature column for our predictions\n",
    "for testCounter in range(0,len(test_user_movie_holder)): ## Setup the range of our loop -- \n",
    "    test_movie = test_user_movie_holder.iloc[testCounter,0] ## Pull out the testing movie_id\n",
    "    test_user = test_user_movie_holder.iloc[testCounter,1] ## Pull out the testing user_id\n",
    "    test_movie_index = columnPlaceKey.index(test_movie) ## Gets our test_movie index for our movie\n",
    "    train_set_holder = data_TRAINING.loc[((data_TRAINING['movie_id'] == test_movie) & (data_TRAINING['user_id'] != test_user))] ## Subset the training set for the movie\n",
    "    train_user_list = list(train_set_holder['user_id'].sort_values()) ## Get the list of users who have rated the movie in the training set\n",
    "    train_mtx_holder = train_user_movie_rating_mtx.iloc[train_user_list,:] ## Gives us all the users from the training set with a rating for the movie\n",
    "    test_user_array = train_user_movie_rating_mtx.iloc[test_user,:] ## Gives us the ratings array for the test user only using training data\n",
    "    train_mtx_holder_FINAL = train_mtx_holder.drop(train_mtx_holder.columns[test_movie_index], axis=1) ## Creates the final user array without the movie in question\n",
    "    test_user_array_FINAL = test_user_array.truncate(test_movie_index) ## Same as above for the user we are predicting\n",
    "    simValueList = [] ## Instantiate our list to hold similarities\n",
    "    for simCounter in range(0,len(train_mtx_holder_FINAL)): ## Go through each row\n",
    "        simValueList.append(euclidean_sim(test_user_array_FINAL,train_mtx_holder_FINAL.iloc[simCounter,:])) ## Calculate simialrity\n",
    "    train_movie_ratings = train_mtx_holder.iloc[:,test_movie_index] ## Get the array of ratings for the movie in questions\n",
    "    predictionHolder = np.average(train_movie_ratings, weights=simValueList) ## Calculate our prediction\n",
    "    test_user_movie_holder.iloc[testCounter,3] = predictionHolder ## Put it into our holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "074c4e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction for movies using euc similairity on any given movie and user RMSE is: 1.029511781937744\n"
     ]
    }
   ],
   "source": [
    "#Let's calculate our RMSE\n",
    "#y_true = np.array(test_user_movie_holder['rating'])\n",
    "results_table['y_pred_euc_sim'] = np.array(test_user_movie_holder['prediction'])\n",
    "RMSE_euc = compute_rmse(results_table['y_true'], results_table['y_pred_euc_sim'])\n",
    "print(f'The prediction for movies using euc similairity on any given movie and user RMSE is: {RMSE_euc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee92e3e9",
   "metadata": {},
   "source": [
    "If we compare the difference in RMSE's between simply taking the average of all users (1.0299732829945336) versus the RMSE of using similarity weighting by user to make a prediction (1.029511781937745), we can see that we don't get nearly as significant a decrease from when we checked against the naive guess of \"3\" for every prediction (1.2401007885881654). However, we need to consider that the \"naive\" guess was fairly accurate which doesn't leave us much room to improve and we made substantial gains from using an unweighted average between all users that did rate a movie, which means there is even less room to improve. That said, let's explore a few more similarity measures to see if they might give us better measures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6714cb4",
   "metadata": {},
   "source": [
    "#### Different Similarity Measures\n",
    "\n",
    "Euclidean 'similairty' is not the only measure of similarity as we can consider others. For the purpose of this capstone, we'll simply consider one more similarity measure, which is the Cosine similarity measure.\n",
    "\n",
    "__Cosine Similarity__\n",
    "\n",
    "Cosine Similarity attempts to derive the virtual \"Cosine\" angle between two vectors in a multi-dimensional space. In plain speak, it basically looks at the \"trend direction\" of two different observations as opposed to where they actually end up (which is what Euclidean similarity does). This is useful in certain problems as it is resistant to \"extreme magnitude\" differences, which can occur with certain problems like comparing documents which may have certain word counts that are extremely different from each other.\n",
    "\n",
    "- Cosine similarity\n",
    "\n",
    "$$ sim(x,y) = \\frac{(x . y)}{\\sqrt{(x . x) (y . y)}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0f2df6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(s1, s2):\n",
    "    \"\"\"Take two pd.Series objects and return their cosine similarity.\"\"\"\n",
    "    if (s1.sum() == 0) or (s2.sum() == 0): ## Account for edge cases to avoid errors\n",
    "        answer = 0\n",
    "    else:\n",
    "        answer = np.sum(s1 * s2) / np.sqrt(np.sum(s1 ** 2) * np.sum(s2 ** 2))\n",
    "    return answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31aa542b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BERKEG~1\\AppData\\Local\\Temp/ipykernel_25960/778637081.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_user_movie_holder['prediction'] = 0 ## Make feature column for our predictions\n"
     ]
    }
   ],
   "source": [
    "#This will be our major process holder that we can simply change with different similarity functions\n",
    "#!!! Warning - This takes a lot of time if you run the entire testing set !!!\n",
    "test_user_movie_holder = data_TESTING[['movie_id','user_id','rating']] ## Create a 'list' of the items to predict\n",
    "test_user_movie_holder['prediction'] = 0 ## Make feature column for our predictions\n",
    "for testCounter in range(0,len(test_user_movie_holder)): ## Setup the range of our loop -- \n",
    "    test_movie = test_user_movie_holder.iloc[testCounter,0] ## Pull out the testing movie_id\n",
    "    test_user = test_user_movie_holder.iloc[testCounter,1] ## Pull out the testing user_id\n",
    "    test_movie_index = columnPlaceKey.index(test_movie) ## Gets our test_movie index for our movie\n",
    "    train_set_holder = data_TRAINING.loc[((data_TRAINING['movie_id'] == test_movie) & (data_TRAINING['user_id'] != test_user))] ## Subset the training set for the movie\n",
    "    train_user_list = list(train_set_holder['user_id'].sort_values()) ## Get the list of users who have rated the movie in the training set\n",
    "    train_mtx_holder = train_user_movie_rating_mtx.iloc[train_user_list,:] ## Gives us all the users from the training set with a rating for the movie\n",
    "    test_user_array = train_user_movie_rating_mtx.iloc[test_user,:] ## Gives us the ratings array for the test user only using training data\n",
    "    train_mtx_holder_FINAL = train_mtx_holder.drop(train_mtx_holder.columns[test_movie_index], axis=1) ## Creates the final user array without the movie in question\n",
    "    test_user_array_FINAL = test_user_array.truncate(test_movie_index) ## Same as above for the user we are predicting\n",
    "    simValueList = [] ## Instantiate our list to hold similarities\n",
    "    for simCounter in range(0,len(train_mtx_holder_FINAL)): ## Go through each row\n",
    "        simValueList.append(cosine_sim(test_user_array_FINAL,train_mtx_holder_FINAL.iloc[simCounter,:])) ## Calculate simialrity\n",
    "    train_movie_ratings = train_mtx_holder.iloc[:,test_movie_index] ## Get the array of ratings for the movie in questions\n",
    "    if sum(simValueList) == 0: ## If we have no similarity with Cosine, then we can't use weighting and we'll default to the average rating\n",
    "        predictionHolder = np.average(train_movie_ratings) ## Calculate our prediction\n",
    "    else:\n",
    "        predictionHolder = np.average(train_movie_ratings, weights=simValueList) ## Calculate our prediction\n",
    "    test_user_movie_holder.iloc[testCounter,3] = predictionHolder ## Put it into our holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4eb9985a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction for movies using cosine similairity on any given movie and user RMSE is: 1.03549395179855\n"
     ]
    }
   ],
   "source": [
    "#Let's calculate our RMSE\n",
    "#y_true = np.array(test_user_movie_holder['rating'])\n",
    "results_table['y_pred_cosine_sim'] = np.array(test_user_movie_holder['prediction'])\n",
    "RMSE_cosine = compute_rmse(results_table['y_true'], results_table['y_pred_cosine_sim'])\n",
    "print(f'The prediction for movies using cosine similairity on any given movie and user RMSE is: {RMSE_cosine}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c41a2d9",
   "metadata": {},
   "source": [
    "The end result of using Cosine Similarity is a RMSE that is worse than Euclidean Distance, which means for now, we'll stick to using the Euclidean Similarity metric to make our predictions if we were to strictly use RMSE as our evaluation metric. In order to faciliate more efficient documentation, we'll save the results to a different file so we can access it more easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4bdaf957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our results so we don't need to replicate this process over and over again\n",
    "results_table.to_csv(\"results_table_FINAL.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c865373",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "In this notebook, we went through and modeled a few ways to predict ratings for a specific user given a specific movie including:\n",
    "\n",
    "* Naive estimate of the median value of the range of possible ratings (i.e., everyone gets a \"3\") which results in a RMSE of about 1.240\n",
    "* An overall average of all the ratings related to a movie in the testing set (i.e., take the average of all the ratings that users supply for a given movie) which results in a RMSE of about 1.030\n",
    "* An average of all ratings related to a movie that is weighted based on how a specific users \"relates\" to the test user (i.e., weight more heavily user ratings that are more similar to the test user). We used two different similarity metrics of Euclidean similarity and Cosine similarity which results in RMSEs of 1.030 and 1.035 respectively\n",
    "\n",
    "We used RMSE as our primary metric for evaluation in this capstone project. Based on this metric, we'd use the Euclidean similarity measure as it did the best (granted only by slighted against just the average rating) against the other methods.\n",
    "\n",
    "This was a lot of fun to learn about and I'm definitely interested in further improving my skill set related to recommendation systems! Cheers! Emre"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
