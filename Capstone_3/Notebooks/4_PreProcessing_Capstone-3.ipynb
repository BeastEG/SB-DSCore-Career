{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3458be4",
   "metadata": {},
   "source": [
    "## 4) Preprocessing and Data Set Creation\n",
    "\n",
    "For our recommender model, we'll need to Preprocess and split our data into a training set and a testing set in order to evaluate it. First, let's quickly evaluate our data to examine if any preprocessing is necessary and if so, what preprocessing we'll do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83c2cae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant base packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe50eff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import our prepped data set\n",
    "raw_df = pd.read_csv('Ratings_Table_COMPLETE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a30b8d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>movie_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>5</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Empire Strikes Back, The (1980)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Gone with the Wind (1939)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>L.A. Confidential (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>Heavyweights (1994)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  user_id  movie_id  rating  timestamp  \\\n",
       "0           0        0       172       5  881250949   \n",
       "1           1        0       133       1  881250949   \n",
       "2           2      196       242       3  881250949   \n",
       "3           3      186       302       3  891717742   \n",
       "4           4       22       377       1  878887116   \n",
       "\n",
       "                       movie_title  \n",
       "0  Empire Strikes Back, The (1980)  \n",
       "1        Gone with the Wind (1939)  \n",
       "2                     Kolya (1996)  \n",
       "3         L.A. Confidential (1997)  \n",
       "4              Heavyweights (1994)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quick peek of data set\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12f75474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100002 entries, 0 to 100001\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   Unnamed: 0   100002 non-null  int64 \n",
      " 1   user_id      100002 non-null  int64 \n",
      " 2   movie_id     100002 non-null  int64 \n",
      " 3   rating       100002 non-null  int64 \n",
      " 4   timestamp    100002 non-null  int64 \n",
      " 5   movie_title  100002 non-null  object\n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#summary stats\n",
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "961ff5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can drop the 'Unamed: 0' column as that is just a repeat\n",
    "raw_df.drop(['Unnamed: 0'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e489786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>movie_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>5</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Empire Strikes Back, The (1980)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Gone with the Wind (1939)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>L.A. Confidential (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>Heavyweights (1994)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp                      movie_title\n",
       "0        0       172       5  881250949  Empire Strikes Back, The (1980)\n",
       "1        0       133       1  881250949        Gone with the Wind (1939)\n",
       "2      196       242       3  881250949                     Kolya (1996)\n",
       "3      186       302       3  891717742         L.A. Confidential (1997)\n",
       "4       22       377       1  878887116              Heavyweights (1994)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e765b21",
   "metadata": {},
   "source": [
    "#### Scaling & Normalization\n",
    "\n",
    "Since our data is in integer form ranging from 1 to 5, it has been effectively scaled and we can move forward with creating our testing and training sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67424cc",
   "metadata": {},
   "source": [
    "#### Data Set Creation Strategy for Training and Testing\n",
    "\n",
    "We will need to consider few things when creating our data set that are potentially different from a traditional \"data set\" project. The most important aspect is the number of ratings available for any given movie. The reason this is important is relatively straight-forward. If a movie has only a single rating, there is no way to have a training/testing split. If a movie only has two ratings, then there can only be one training observation and one testing observation. This is not a typical consideration for most data sets as you typically have enough observations per category that you can easily split via training/testing and be able to do something like 80/20 split between testing and training. With a recommender system like this, we'll need a more explicit strategy. We will use the following strategy for splitting in terms of counts to drop.\n",
    "\n",
    "* If a movie only has a single rating, there is no way to have a meaningful train/test split and therefore we'll drop these movies from our test/train data set creation\n",
    "* If a movie only has two ratings, the test/train split will result in simply in a replication prediction (i.e., simply duplicate the ratings of the training value as the prediction). There isn't much of a model that can be created from this situation so we'll drop these movies as well.\n",
    "\n",
    "This means that in order for a movie to even have a feasible model for our train/test split, we'll need at least three observations. It may (or may not) make sense to consider these very small ratings count from a model efficiency and effectiveness perspective.\n",
    "\n",
    "__Note on Training / Testing Split__\n",
    "\n",
    "The difficulty of this step is explicitly tied to the number of ratings you have per movie and the ability of the sponser to gain more access to ratings if necessary. For example, a large organization like Netflix may have a substantial amount of ratings per movie that you can more easily apply a traditional 80/20 split without much considerations. For a newer organization, that may not necessarily be easily achieveable if they do not have a lot of movies (or product sales, product reviews, etc.) so they'll need a more detailed strategy for dealing with a situation where each given item only has a very sparse amount of ratings. In addition, the ability of the sponser to get more ratings needs to be considered. For example, an organization like Netflix can potentially push to gather ratings quickly and effectively to get enough ratings for any movie to have enough ratings to meet a minimum threshold but a different organization may not have that luxury.\n",
    "\n",
    "This needs to be considered in the light out our sponsor where (we learned from EDA that) 50% of the movies only have 27 ratings  or less. This means if we set a threshold of needing 30 movie ratings to make it \"model valid\", we'd be throwing out many possible movies and creating a model that wouldn't be particularly useful to the current state of our sponsor. Therefore, we'll implement the following strategy for our train/test split.\n",
    "\n",
    "* We'll drop the movies with only one or two ratings as mentioned above since we'll have no way to effectively model a relationship with such sparse data\n",
    "* For every four movies in the training set, a fifth movie will be the testing set (to virtually replicate a 80/20 split)\n",
    "* In the event we have a movie with more than two ratings but less than five ratings:\n",
    "\n",
    "    * If our movie only has three ratings, we'll have the training set get two observations and the testing set get the last observations\n",
    "    * If our movie only has four ratings, we'll have the training set get three observations and the testing set get the last observations\n",
    "    \n",
    "* Once we get to greater than five movies, we'll implement the following split for the remainder after every five ratings:\n",
    "\n",
    "    * If our Mod 5 == 1, we'll put that remainder in the testing set\n",
    "    * If our Mod 5 == 2, we'll split them one for training and one for testing\n",
    "    * If our Mod 5 == 3, we'll split them two for training and one for testing\n",
    "    * If our Mod 5 == 4, we'll split them two for training and two for testing\n",
    "\n",
    "While this strategy will not always emulate a 80/20 split, it should give us enough of a spread for training and testing to create a model that is relevant to our sponsor given their own data spread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "579e70da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, let's make a list of the number of ratings per movie\n",
    "movieId_RatingsCount = raw_df[['movie_id','rating']].groupby('movie_id').count()\n",
    "movieId_RatingsCount_Sorted = movieId_RatingsCount.sort_values('rating',ascending=False)\n",
    "movieId_RatingsCount_Sorted['rating_count'] = movieId_RatingsCount_Sorted['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4cca7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second, let's pick out the movies that have more than two ratings\n",
    "movieId_KeepList = movieId_RatingsCount_Sorted.loc[movieId_RatingsCount_Sorted['rating_count'] > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72dda2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third, let's create a list of the movie IDs\n",
    "movieId_KeepList = movieId_KeepList.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18213bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's drop the movies that do not have enough ratings\n",
    "data_table_complete = raw_df.loc[raw_df['movie_id'].isin(movieId_KeepList)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a532f8e1",
   "metadata": {},
   "source": [
    "To make our labels, we'll have to consider two main loops. The first loop will work through each movieID and the second loop we'll then randomly assign each observation within the movieID to either the training set or training set. We'll create a feature called 'testing' that is '1' if the observation is assigned to testing and '0' if assigned to training. It will also be easiest to concatenate each progressive subset of movieIDs as opposed to changing the original complete data table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95459c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BERKEG~1\\AppData\\Local\\Temp/ipykernel_21180/3581013495.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_table_complete['testing'] = 0\n"
     ]
    }
   ],
   "source": [
    "#First, let's add a feature for assignment\n",
    "data_table_complete['testing'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99e54981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's build our sorting algorithm components\n",
    "#First, let's make a movie list\n",
    "movieID_List = set(data_table_complete['movie_id'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "598337c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant packages\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab1f53d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's make an empty dataframe that will be the final holder of all our processign\n",
    "data_table_ASSIGNED_COMPLETE = pd.DataFrame(columns = data_table_complete.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a7481b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second, we need to create a tool to randomly assign observations based on the number of observations we have. \n",
    "# Remember that a '1' goes to testing and a '0' goes to training\n",
    "def assign_to_set(df):\n",
    "    obs_num = len(df)  ## Get the number of observations we have\n",
    "    assign_list = [] ## Instantiate our list\n",
    "    if obs_num == 3: ## Handle only 3 observations\n",
    "        assign_list = [0,0,1]\n",
    "    elif obs_num == 4: ## Handle only 4 observations\n",
    "        assign_list = [0,0,0,1]\n",
    "    else:\n",
    "        quot = obs_num // 5  ## Get the mulitples of 5\n",
    "        remn = obs_num % 5  ## Get the remainder\n",
    "        for counter in range (0,quot):\n",
    "            assign_list = assign_list + [0,0,0,0,1] ##Build based on multiples\n",
    "        if remn == 1:\n",
    "            assign_list = assign_list + [0]\n",
    "        elif remn == 2:\n",
    "            assign_list = assign_list + [0,1]\n",
    "        elif remn == 3:\n",
    "            assign_list = assign_list + [0,0,1]\n",
    "        elif remn == 4:\n",
    "            assign_list = assign_list + [0,0,1,1]\n",
    "    random.shuffle(assign_list) ## Shuffle the list\n",
    "    return assign_list ## Return the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c055500",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now let's build our complete algorithm to assign movies\n",
    "for movie in movieID_List:\n",
    "    df_subset = data_table_complete.loc[data_table_complete['movie_id'] == movie].copy() ## Make a subset dataframe\n",
    "    assign_list = assign_to_set(df_subset) ## Get our new assignment list\n",
    "    df_subset['testing'] = assign_list ## Update the testing list\n",
    "    data_table_ASSIGNED_COMPLETE = pd.concat([data_table_ASSIGNED_COMPLETE,df_subset],axis=0) ## Concatenate the new DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1736db82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now let's give it a cursory check to make sure the algorithm worked properly by checking a random movie\n",
    "len(data_table_ASSIGNED_COMPLETE.loc[data_table_ASSIGNED_COMPLETE['movie_id'] == 56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cdaa116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_table_complete.loc[data_table_complete['movie_id'] == 56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25257800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "testing\n",
       "0    314\n",
       "1     80\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Okay, at least the lengths make sense, so let's see the counts of testing\n",
    "data_table_ASSIGNED_COMPLETE.loc[data_table_ASSIGNED_COMPLETE['movie_id'] == 56].value_counts('testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cb00d6",
   "metadata": {},
   "source": [
    "Alright, let's check if the function worked properly. 394 divided by 5 results in 78 R 4, which we can then count the number of zeroes that should come out of it. 78 * 4 = 312 and then two more zeroes makes 314 zeroes. For the ones, we get 78 + 2 which is 80. This gives us confidence that the algorithm is working properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f81cb2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can split our new DataFrame into a training set and a testing set\n",
    "data_table_TRAINING = data_table_ASSIGNED_COMPLETE.loc[data_table_ASSIGNED_COMPLETE['testing'] == 0]\n",
    "data_table_TESTING = data_table_ASSIGNED_COMPLETE.loc[data_table_ASSIGNED_COMPLETE['testing'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "546d7236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's now save these data sets\n",
    "data_table_TRAINING.to_csv('DF_TRAINING.csv')\n",
    "data_table_TESTING.to_csv('DF_TESTING.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d04c7c",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "Alright, we've preprocessed our data (which was relatively simple since our data was already scaled by virtue of it being on a 1 to 5 scale) and seperated our data set accordingly to ensure we have enough training data for our testing data based on the movie. In a more realistic setting, you'd probably have to heavily consider the amount of minimum movie ratings you'd want to justify modeling it. In addition, the randominzation may need to be consider in light of how many movies you have. If you're randomizing on just 5 movies for example, whichever movies are select for the training and testing sets can have significant impacts on accuracy (for example, imagine if an 'odd-ball' rating becomes the single testing set against the other four ratings which are more sensical versus the odd-ball is in the training set and can be at least somewhat correct by the other training observations). For this capstone, we won't get into it, but it is something to consider going forward as well. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
